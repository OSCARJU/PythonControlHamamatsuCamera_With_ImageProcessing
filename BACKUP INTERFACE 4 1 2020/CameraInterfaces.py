#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Programme Edited
"""

from __future__ import print_function
import sys
import hamamatsu_camera as hc
import abc
import threading
try:
    import queue as Queue
except ImportError:
    import Queue as Queue
import cv2
import numpy as np
import pyqtgraph as pg
import time
import datetime
import json
import tifffile
from tifffile import imsave
import multiprocessing
import traceback
import pickle
import matplotlib
import cv2
import os


class BaseCamera(threading.Thread):
    """Base class for all types of cameras"""
    __metaclass__ = abc.ABCMeta

    def __init__(self):
        threading.Thread.__init__(self)

    @abc.abstractmethod
    def run(self):
        pass

    @abc.abstractmethod
    def end(self):
        pass

    @property
    def framerate(self):
        return self._framerate

    @framerate.setter
    def framerate(self, framerate):
        self._framerate = framerate


class BasePreview:
    """Base class to display a preview of a frame from the camera using the ImageView class from pyqtgraph"""
    def __init__(self):
        self.iv = pg.imageview.ImageView()

        colors = [
            (0, 0, 0),
            (7, 0, 220),
            (236, 0, 134),
            (246, 246, 0),
            (255, 255, 255),
            (0, 255, 0)
        ]

        #cmap = pg.ColorMap(pos=np.linspace(0.0, 1.0, 6), color=colors)
        #self.iv.setColorMap(cmap)
        self.iv.setLevels(0, 256)
        self.hist = self.iv.getHistogramWidget()
        self.hist.vb.enableAutoRange(self.hist.vb.YAxis, True)
        self.iv.show()

    def update_preview(self, img):
        self.iv.setImage(img, autoRange=False, autoLevels=False, autoHistogramRange=False)


class ImageFuncs:
    """Misc image functions"""
    @staticmethod
    def create_LUT_8bit(levels, src_depth):
        """
        :param src_depth:   bit depth of the source
        :type src_depth:    int
        :param levels:      min and max levels with which to create the LUT
        :type levels:       tuple
        :return:            8 bit LUT to convert the source's bit depth to 8 bit
        :rtype:             np.ndarray
        """

        accepted_depths = [16, 32, 64]
        if src_depth not in accepted_depths:
            raise TypeError('Can only convert from uint16, uint32, or uint64')
        depth = 'uint' + str(src_depth)
        LUT = np.arange(2**src_depth, dtype=depth)
        LUT.clip(levels[0], levels[1], out=LUT)
        LUT -= levels[0]
        print("LUT is: ")
        print(LUT)
        print("levels is: ")
        print(levels)
        print("denominator is")
        print((levels[1] - levels[0] + 1) / 256)
#        pickle.dump(LUT, open('F:\LUT.pickle', 'wb'))
#        pickle.dump(levels, open('F:\levels.pickle', 'wb'))
        np.floor_divide(LUT, (levels[1] - levels[0] + 1) / 256, out=LUT, casting='unsafe')
            

        return LUT.astype(np.uint8)

    @staticmethod
    def apply_8bit_LUT(image, LUT):
        """
        :param image:   The image upon which to apply the LUT and change its bit depth
        :type image:    np.ndarray
        :param LUT:     The 8bit LUT to use for downscaling the bit depth. Generated by ImageFuncs.create_LUT_8bit
        :type LUT:      np.ndarray
        :return:        Downscaled 8 bit image with the LUT applied to it
        :rtype:         np.ndarray
        """
        return np.take(LUT, image).astype(np.uint8)


class BaseWriter(threading.Thread):
    """Base class that contains methods for converting 16 bit to 8 bit grey-scale frames and saving metadata"""
    def __init__(self, threading_queue, filename, compression_level=1, levels=(0, 65535), metadata={}):
        threading.Thread.__init__(self)
        assert isinstance(threading_queue, Queue.Queue)
        self.q = threading_queue
        self.filename = filename
        self.comp_lev = compression_level
        self.levels = levels
        self.metadata = metadata
        if 'framerate' not in self.metadata.keys():
            try:
                self.metadata['framerate'] = 1/self.metadata['exposure']
            except KeyError:
                raise KeyError('Exposure or Framerate must be specified to save as metadata')

        #self.tiff_writer = tifffile.TiffWriter(filename, bigtiff=True, append=True)

    @abc.abstractmethod
    def run(self):
        pass

    @abc.abstractmethod
    def end(self):
        pass

    # def create_LUT_8bit(self, src_depth):
    #     """
    #     :param src_depth:   bit depth of the source
    #     :return:            8 bit LUT to convert the source's bit depth to 8 bit
    #     :rtype:             np.ndarray
    #     """
    #     accepted_depths = [16, 32, 64]
    #     if src_depth not in accepted_depths:
    #         raise TypeError('Can only convert from uint16, uint32, or uint64')
    #     depth = 'uint' + str(src_depth)
    #     LUT = np.arange(2**src_depth, dtype=depth)
    #     LUT.clip(self.levels[0], self.levels[1], out=LUT)
    #     LUT -= self.levels[0]
    #     np.floor_divide(LUT, (self.levels[1] - self.levels[0] + 1) / 256,
    #                     out=LUT, casting='unsafe')
    #     return LUT.astype(np.uint8)
    #
    # def apply_8bit_LUT(self, image, LUT):
    #     return np.take(LUT, image).astype(np.uint8)

    def save_metadata(self, filename):
        date = datetime.datetime.fromtimestamp(time.time())
        ymd = date.strftime('%Y%m%d')
        hms = date.strftime('%H%M%S')

        meta = {'framerate':    self.metadata['framerate'],
                'source':       'Particle Visualization firmware OSC1605 v1.0',
                'version':      self.metadata['version'],
                'date':         ymd,
                'time':         hms,
                'stims':        self.metadata['stims'],
                'level_min':    int(self.metadata['levels'][0]),
                'level_max':    int(self.metadata['levels'][1]),
                'Number_of_Frames':  self.metadata['NumberOfFrames'],
                'Lapse time':        self.metadata['LapseTime']}


        if filename.endswith('.tiff'):
            json_file = filename[:-5] + '.json'
        elif filename.endswith('.tif'):
            json_file = filename[:-4] + '.json'
        else:
            raise ValueError
        with open(json_file, 'w') as f:
            json.dump(meta, f)
            print('end')


class InfoHamamatsu(BaseCamera):
    """Base class for Hamamatsu cameras"""
    __metaclass__ = abc.ABCMeta

    def __init__(self, **kwargs):
        BaseCamera.__init__(self)
        self.model= hc.InfoCamera()






class BaseHamamatsu(BaseCamera):
    """Base class for Hamamatsu cameras"""
    __metaclass__ = abc.ABCMeta

    def __init__(self, **kwargs):
        BaseCamera.__init__(self)
        if 'exposure' not in kwargs.keys():
            raise KeyError('No exposure value specified')
        #params = {'model': model, 'exposure': exp, 'contrast': contra, 'bits': bits, 'binning': binning, 'x0pos': x0pos,
         #         'y0pos': y0pos, 'width': width, 'height': height}
        #if(self.hcam.getModelInfo(0)=='C11440-36U'):
         #   print('oscar')
        InfoHamamatsu.__init__(self)
        #print('print model cameras')
        #print(self.model[0])
        #print(self.model[1])
        #print('camera selected')
        #print(kwargs['model'])
        # configurate camera based on the input model
        if(self.model[0] == kwargs['model']):
            self.hcam = hc.HamamatsuCameraMR(0)
        if (self.model[1] == kwargs['model']):
            self.hcam = hc.HamamatsuCameraMR(1)
        #readout depends on the camera model

        if(self.hcam.getModelInfo(0)=='C11440-36U'):
            readout_speed = 1
        if (self.hcam.getModelInfo(0) == 'C13440-20CU'):
            readout_speed = 2 #it also possible to use 1

        # configuration for camera in place 0
        #self.hcam = hc.HamamatsuCameraMR(0)
        # configuration for camera in place 1
        self.camera_open = True

        cam_offset = 100
        ##hamamatsu orca
        #print("camera 1")
        #print(self.hcam.getModelInfo(0))
        #print("camera 2")
        #print(self.hcam.getModelInfo(1))
        #print("camera 3")
        #print(self.hcam.getModelInfo(2))
        #cam_x = 2048
        #cam_y = 2048
        #readout_speed = 2
        ##hamamatsu spark
        cam_x = 1920
        cam_y = 1200
        self.exposure = kwargs['exposure']
        #SET SENSOR MODE
        #self.hcam.setPropertyValue("sensor_mode", 1)
        # correct_mode internal camera
        self.hcam.setPropertyValue("defect_correct_mode", "ON")
        # contrast
        self.contrast = kwargs['contrast']
        #self.hcam.setPropertyValue('contrast_gain', self.Contrast)
        # bits

        self.Bits = kwargs['bits']
        if (self.Bits == '8'):
            self.bits = 256.0
        if (self.Bits == '10'):
            self.bits = 1024.0
        if (self.Bits == '12'):
            self.bits = 4096.0
        if (self.Bits == '14'):
            self.bits = 16384.0
        if (self.Bits == '16'):
            self.bits = 65536.0
        #print('binning number')
        #print(kwargs['binning'])
        # binning pixels
        if (kwargs['binning'] == 'Customize'):
            self.vsize = kwargs['height']
            self.hsize = kwargs['width']
        self.binning = kwargs['binning']

        #if ( self.Binning == '1'):
        #    self.hcam.setPropertyValue("binning", "1x1")
        #    self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0]
        #    self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0]
        #if ( self.Binning == '2'):
        #    self.hcam.setPropertyValue("binning", "2x2")
        #    self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0]/2
        #    self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0]/2
        #if ( self.Binning == '3'):
        #    self.hcam.setPropertyValue("binning", "3x3")
        #    self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0] / 3
        #    self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0] / 3
        #if ( self.Binning == '4'):
        #    self.hcam.setPropertyValue("binning", "4x4")
        #    self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0] / 4
        #    self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0] / 4
        #if ( self.Binning == 'Customize'):
        #    self.VeSize = kwargs['height']
        #    self.HoSize = kwargs['width']
        #    self.hcam.setPropertyValue("subarray_hsize",   self.VeSize )
        #    self.hcam.setPropertyValue("subarray_vsize",  self.HoSize)
        #    self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0]
        #    self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0]

        #set Xposition and Y0POSITION
        self.hcam.setPropertyValue("subarray_hpos", kwargs['x0pos'])
        self.hcam.setPropertyValue("subarray_vpos", kwargs['y0pos'])
        #set size of image
        #self.hcam.setPropertyValue("subarray_hsize",  kwargs['height'])
        #self.hcam.setPropertyValue("subarray_vsize",  kwargs['width'])

        bit_perchannel = "8BIT"
        #self.hcam.setPropertyValue("bits_per_chanel", 12)
        #self.hcam.setPropertyValue("binning", "2x2")
        #set read out speed depending of camera
        self.hcam.setPropertyValue("readout_speed", readout_speed)
        #orca spark doesnt have this function
        #bit per channel can change from 12 to 16 step 4 only orca flash, default 16
        #set highest value of bit per channel
        self.hcam.setPropertyValue('bit_per_channel', 16)
        #image pixel type only change in orca flas 1 = mono8, 2 = mono16 default, or 3 mono12
        # set highest value of image_pixel_type
        self.hcam.setPropertyValue("image_pixel_type",2 )
        #self.hcam.setPropertyValue('contrast_gain', 200)

        #print("getCameraProperties")
        #print(self.hcam.getCameraProperties())
        #print("image_pixel_type")
        #print(self.hcam.getPropertyValue('image_pixel_type'))
        #print("bit_per_channel")
        #print(self.hcam.getPropertyValue('bit_per_channel'))
        #print("readout_speed")
        #print(self.hcam.getPropertyValue('readout_speed'))
        #print("binning")
        #print(self.hcam.getPropertyValue('binning'))
        #print("exposure_time")
        #print(self.hcam.getPropertyValue('exposure_time'))
        #print("contrast_gain")
        #print(self.hcam.getPropertyValue('contrast_gain'))
        #print("internal_frame_rate")
        #print(self.hcam.getPropertyValue('internal_frame_rate'))
        #print("subarray_hsize")
        #print(self.hcam.getPropertyValue('subarray_hsize'))
        #print("subarray_vsize")
        #print(self.hcam.getPropertyValue('subarray_vsize'))
        #print("subarray_vpos")
        #print(self.hcam.getPropertyValue('subarray_vpos'))
        #print("subarray_hpos")
        #print(self.hcam.getPropertyValue('subarray_hpos'))
        #print("self.bits")
        #print(self.bits)
        #print('sensor_mode')
        #print(self.hcam.getPropertyValue('sensor_mode'))
        #print('readout_speed')
        #print(self.hcam.getPropertyValue('readout_speed'))
        #print('readout_direction')
        #print(self.hcam.getPropertyValue('readout_direction'))





    @property
    def exposure(self):
        e = self.hcam.getPropertyValue("exposure_time")
        return e

    @exposure.setter
    def exposure(self, e):
        self.hcam.setPropertyValue("exposure_time", e)
        self.framerate = 1/e

    @property
    def contrast(self):
        e = self.hcam.getPropertyValue('contrast_gain')
        return e

    @contrast.setter
    def contrast(self, e):
        self.hcam.setPropertyValue('contrast_gain', e)
        #self.framerate = 1 / e

    @property
    def binning(self):
        e = self.hcam.getPropertyValue("binning")
        return e

    @binning.setter
    def binning(self, e):
        if ( e== '1'):
            self.hcam.setPropertyValue("binning", "1x1")
            self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0]
            self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0]
        if ( e == '2'):
            self.hcam.setPropertyValue("binning", "2x2")
            self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0]/2
            self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0]/2
        if ( e == '3'):
            self.hcam.setPropertyValue("binning", "3x3")
            self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0] / 3
            self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0] / 3
        if ( e == '4'):
            self.hcam.setPropertyValue("binning", "4x4")
            self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0] / 4
            self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0] / 4
        if ( e == 'Customize'):
            self.Vsize = self.hcam.getPropertyValue('subarray_vsize')[0]
            self.Hsize = self.hcam.getPropertyValue('subarray_hsize')[0]
        # self.framerate = 1 / e

    @property
    def hsize(self):
        e = self.hcam.getPropertyValue("subarray_hsize")
        return e

    @hsize.setter
    def hsize(self, e):
        self.hcam.setPropertyValue("subarray_hsize", e)
        #self.framerate = 1 / e

    @property
    def vsize(self):
        e = self.hcam.getPropertyValue("subarray_vsize")
        return e

    @vsize.setter
    def vsize(self, e):
        self.hcam.setPropertyValue("subarray_vsize", e)
        # self.framerate = 1 / e


    def get_grey_values(self):
        """
        :rtype: np.ndarray
        :return: 1D numpy array of grey values
        """

        [frame, dim] = self.hcam.getFrames()
        #print('frame')
        #print(frame)
        #print('dim')
        #print(dim)
        grey_values = frame[0].getData()
        return grey_values

    @abc.abstractmethod
    def end(self):
        self.hcam.stopAcquisition()
        self.hcam.shutdown()
        self.camera_open = False


class BaseOpenCV(BaseCamera):
    """
    Adapted from Daniel Dondorp
    Base class for OpenCV compatible cameras
    """
    __metaclass__ = abc.ABCMeta

    def __init__(self, camera=0, framerate=30, shape=(7680, 4320), exposure=-5.0):
        """
        :param camera: Which connected camera to use.
        :param framerate:
        :param shape:
        :param brightness:
        :param exposure: negative values, get evaluates  as 2**param_val by camera.
        """
        BaseCamera.__init__(self)
        self.camera = camera
        self.cap = cv2.VideoCapture(self.camera)
        self.alive = False
        self.framerate = framerate
        self.shape = shape

        self.aperture = self.cap.get(cv2.CAP_PROP_APERTURE)
        self.exposure = exposure

    @property
    def framerate(self):
        return self._framerate

    @framerate.setter
    def framerate(self, framerate):
        self._framerate = framerate
        self.cap.set(cv2.CAP_PROP_FPS, framerate)

    @property
    def shape(self):
        return self._shape

    @shape.setter
    def shape(self, shape):
        self._shape = shape
        w, h = shape
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, w)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h)
        # print("Video shape set to : ", w, h)

    @property
    def exposure(self):
        return self._exposure

    @exposure.setter
    def exposure(self, exposure):
        self._exposure = exposure
        self.cap.set(cv2.CAP_PROP_EXPOSURE, exposure)

    def reconnect(self):
        self.cap.release()
        self.cap = cv2.VideoCapture(self.camera)

    def read(self):
        ret = False
        while ret == False:
            ret, frame = self.cap.read()

        return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    def end(self):
        self.cap.release()


class PreviewOpenCV(BaseOpenCV, BasePreview):
    """
    Adapted from Daniel Dondorp
    """
    def __init__(self):
        BaseOpenCV.__init__(self)
        BasePreview.__init__(self)
        super(PreviewOpenCV, self).__init__(BasePreview)

    def run(self):
        print("Preview Starting")
        self.alive = True

        frames = 0
        start_time = time.time()

        while self._alive:

            ret, frame = self.cap.read()

            if ret:
                self.update_preview(frame)

            frames += 1
            if frames == 10:
                end_time = time.time()
                total_time = (end_time - start_time)
                fps = frames / total_time
                sys.stdout.write("\r fps = " + str(fps) + " time for 10 frames: " + str(total_time))
                frames = 0
                start_time = time.time()
        self.iv.close()
        super(PreviewOpenCV, self).end()

    def end(self):
        self._alive = False


class AcquireOpenCV(BaseOpenCV):
    """
    Adapted from Daniel Dondorp
    """
    def __init__(self):
        BaseOpenCV.__init__(self)

    def run(self, name="out", duration=60):
        w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        framerate = self.framerate

        savepath = name + ".avi"

        fourcc = cv2.VideoWriter_fourcc(*"XVID")
        out = cv2.VideoWriter(savepath, fourcc, framerate, (w, h), isColor=False)

        start_time = time.time()
        end_time = start_time
        self.alive = True
        fc = 0
        while (end_time - start_time) < duration and self.alive:

            ret, frame = self.cap.read()

            if ret:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                out.write(frame)
                fc += 1
                cv2.imshow('Recording', frame)

            end_time = time.time()
            sys.stdout.write("\r Recording! " + str(np.round((end_time - start_time), 2)) + "/" + str(
                duration) + " seconds       ")

        else:
            sys.stdout.write("\n Recording Complete! Saved as " + name + "Framecount: " + str(fc))

            cv2.destroyWindow("Recording")
            out.release()
            self.alive = False


class PreviewHamamatsu(BaseHamamatsu, BasePreview):
    def __init__(self, **kwargs):
        BaseHamamatsu.__init__(self, **kwargs)
        BasePreview.__init__(self)
        print("example")
        print(kwargs['exposure'])
        print("example")
        print(kwargs['subtractor'])
        print("example")
        print(kwargs['image_display'])
        self.subtractor = kwargs['subtractor']
        self.imagedisplay = kwargs['image_display']
        self.lapse = kwargs['lapse']
        self._show_preview = True
        #BACKGROUND CNT
        self.fgbg = cv2.bgsegm.createBackgroundSubtractorCNT(minPixelStability=15,
                                                            useHistory=True,
                                                            maxPixelStability=15 * 60,
                                                            isParallel=True)
        #BACKGROUND GMG
        self.fgbgGMG = cv2.bgsegm.createBackgroundSubtractorGMG(initializationFrames=1,
                                                                decisionThreshold=0.8)
        #BackgroundGSOC
        self.fgbgGSOC = cv2.bgsegm.createBackgroundSubtractorGSOC(nSamples=20,
                                                                 replaceRate=0.003,
                                                                 propagationRate=0.01,
                                                                 hitsThreshold=32,
                                                                 alpha=0.01,
                                                                 beta=0.0022,
                                                                 blinkingSupressionDecay=0.1,
                                                                 blinkingSupressionMultiplier=0.1,
                                                                 noiseRemovalThresholdFacBG=0.0004,
                                                                 noiseRemovalThresholdFacFG=0.0008)
        #BackgroundKNN
        self.fgbgKNN = cv2.createBackgroundSubtractorKNN(history=500,
                                                         dist2Threshold=400.0,
                                                         detectShadows=True)
        #BackgroundLSBP
        self.fgbgLSBP = cv2.bgsegm.createBackgroundSubtractorLSBP(nSamples=20,
                                                                LSBPRadius=16,
                                                                Tlower=2.0,
                                                                Tupper=32.0,
                                                                Tinc=1.0,
                                                                Tdec=0.05,
                                                                Rscale=10.0,
                                                                Rincdec=0.005,
                                                                noiseRemovalThresholdFacBG=0.0004,
                                                                noiseRemovalThresholdFacFG=0.0008,
                                                                LSBPthreshold=8,
                                                                minCount=2)
        #BackgroundMOG
        self.fgbgMOG = cv2.bgsegm.createBackgroundSubtractorMOG(history=200,
                                                                nmixtures=5,
                                                                backgroundRatio=0.7,
                                                                noiseSigma=0)
        self.fgbgMOG2 = cv2.createBackgroundSubtractorMOG2(history=500,
                                                          varThreshold=16,
                                                          detectShadows=True)

    def run(self):
        self.hcam.startAcquisition()
        first_img = True
        first_imgR = True
        first_imgFL = True
        first_imgF = True
        first_imgMOG = True
        first_imgGMG = True
        cont = 0
        # Background subtraction using CNT

        while self._show_preview:
            try:
                ##img = np.reshape(self.get_grey_values(), (1200, 1920))

                #
                Vsize = int(self.Vsize)
                Hsize = int(self.Hsize)
                #print('size v')
                #print(Vsize)
                #print('size h')
                #print(Hsize)
                #print('self.get_grey_values()')
                #print(self.get_grey_values().dtype)
                #img = np.reshape(self.get_grey_values(), (600, 960))
                img = np.reshape(self.get_grey_values(), (Vsize, Hsize))

                #img = cv2.flip(img,0)
                img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
                #print(self.hcam.getPropertyValue('internal_frame_rate'))

                #img = cv2.convertScaleAbs(img, alpha=(256.0 / 256.0))
                #bits to interpolate the intensity
                bits = self.bits
                #print('bits used')
                #print(bits)
                #img = ImageFuncs.apply_8bit_LUT(img, self.LUT_8bit)
                img = cv2.convertScaleAbs(img, alpha=(256.0 / bits))
                #'subtractor': subtractor
                #'image_display': image_display

                if (self.subtractor <= 8):
                    if (self.subtractor == 3):
                        if (self.subtractor == 3 and self.imagedisplay ==3 ):
                            if first_imgGMG:
                                self.ForegroundGMG = img
                                first_imgGMG = False
                            else:
                                self.ForegroundGMG = self.ImageBackground(img, self.subtractor, self.imagedisplay)
                            img = self.ForegroundGMG
                        else:
                            first_imgGMG = True
                            img = self.ImageBackground(img, self.subtractor, self.imagedisplay)
                    if (self.subtractor == 7):
                        if (self.subtractor == 7 and self.imagedisplay ==3 ):
                            if first_imgMOG:
                                self.ForegroundMOG = img
                                first_imgMOG = False
                            else:
                                self.ForegroundMOG = self.ImageBackground(img, self.subtractor, self.imagedisplay)
                            img = self.ForegroundMOG
                        else:
                            first_imgMOG = True
                            img = self.ImageBackground(img, self.subtractor, self.imagedisplay)
                    if (self.subtractor != 3 and self.subtractor != 7 ):
                        first_imgGMG = True
                        first_imgMOG = True
                        img = self.ImageBackground(img, self.subtractor, self.imagedisplay)

                #Running fuzzy  lineal
                if (self.subtractor == 10):
                    Thu = 30
                    Ths = 5
                    Thfs = 0.4
                    alphamin = 0.9
                    Height, Width = img.shape
                    InputImage = np.asarray(img, dtype=np.float32)
                    if first_imgFL:
                        Background_Image = InputImage
                        Background_Updated = np.zeros((Height, Width))
                        Background_Updated = np.asarray(Background_Updated,
                                                        dtype=np.float32)
                        Result_Comparison = np.zeros((Height, Width))
                        Result_Comparison = np.asarray(Result_Comparison,
                                                       dtype=np.float32)
                        Background_Substraction = np.zeros((Height, Width))
                        Background_Substraction = np.asarray(Result_Comparison,
                                                             dtype=np.float32)
                        alpha = np.zeros((Height, Width))
                        alpha = np.asarray(Result_Comparison,
                                           dtype=np.float32)
                        Saturating_Limiter = np.zeros((Height, Width))
                        Saturating_Limiter = np.asarray(Saturating_Limiter, dtype=np.float32)
                        Fuzzy_Background_Substraction = np.zeros((Height, Width))
                        Fuzzy_Background_Substraction = np.asarray(Saturating_Limiter, dtype=np.float32)
                        first_imgFL = False

                    else:
                        Result_Comparison = np.absolute(np.subtract(InputImage,
                                                                    Background_Image))
                        Saturating_Limiter = np.divide(Result_Comparison, Ths)
                        Fuzzy_Background_Substraction = np.where(Result_Comparison > Ths,
                                                                 np.ones((Height, Width)),
                                                                 Saturating_Limiter)
                        Abs_LPF_Fuzzy_Background_Substraction = np.absolute(cv2.blur(
                            Fuzzy_Background_Substraction, (3, 3)))

                        Background_Substraction = np.where(Abs_LPF_Fuzzy_Background_Substraction > Thfs,
                                                           np.ones((Height, Width)), 0)
                        alpha = 1 + np.multiply(0.1, (np.subtract(Fuzzy_Background_Substraction, 1)))
                        Background_Updated = np.add(np.multiply(alpha, Background_Image), np.multiply(
                            (1 - alpha), InputImage))
                        Background_Image = Background_Updated
                    if (self.imagedisplay == 1):
                        img = img
                    if (self.imagedisplay == 2):
                        img = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                    if (self.imagedisplay == 3):
                        img = np.asarray(Background_Image, dtype=np.uint8)
                    if (self.imagedisplay == 4):
                        bmg = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                        fmg = np.asarray(Background_Image, dtype=np.uint8)
                        # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                        img = cv2.addWeighted(fmg, 0.25,
                                              (np.where(bmg > fmg, img, 0)), 0.75, 0)

                    #imb = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                        #img = cv2.addWeighted(imb, 0.25,img, 0.75, 0)
                else:
                    first_imgFL = True



                # Running Fuzzy logic
                if (self.subtractor == 11):
                    Thu = 30
                    Ths = 30
                    Thfs = 0.4
                    alphamin = 0.9
                    Height, Width = img.shape
                    InputImage = np.asarray(img, dtype=np.float32)
                    if first_imgF:
                        Background_Image = InputImage
                        Background_Updated = np.zeros((Height, Width))
                        Background_Updated = np.asarray(Background_Updated,
                                                        dtype=np.float32)
                        Result_Comparison = np.zeros((Height, Width))
                        Result_Comparison = np.asarray(Result_Comparison,
                                                       dtype=np.float32)
                        Background_Substraction = np.zeros((Height, Width))
                        Background_Substraction = np.asarray(Result_Comparison,
                                                             dtype=np.float32)
                        alpha = np.zeros((Height, Width))
                        alpha = np.asarray(Result_Comparison,
                                           dtype=np.float32)
                        Saturating_Limiter = np.zeros((Height, Width))
                        Saturating_Limiter = np.asarray(Saturating_Limiter, dtype=np.float32)
                        Fuzzy_Background_Substraction = np.zeros((Height, Width))
                        Fuzzy_Background_Substraction = np.asarray(Saturating_Limiter, dtype=np.float32)
                        first_imgF = False
                    else:
                        Result_Comparison = np.absolute(np.subtract(InputImage,
                                                                    Background_Image))
                        Saturating_Limiter = np.divide(Result_Comparison, Ths)
                        Fuzzy_Background_Substraction = np.where(Result_Comparison > Ths,
                                                                 np.ones((Height, Width)),
                                                                 Saturating_Limiter)
                        Abs_LPF_Fuzzy_Background_Substraction = np.absolute(cv2.blur(
                            Fuzzy_Background_Substraction, (3, 3)))
                        Background_Substraction = np.where(Abs_LPF_Fuzzy_Background_Substraction > Thfs,
                                                           np.ones((Height, Width)), 0)
                        alpha = np.subtract(1, np.multiply(
                            (1 - alphamin), np.exp(np.multiply(-5, Fuzzy_Background_Substraction))))
                        Background_Updated = np.add(np.multiply(alpha, Background_Image), np.multiply(
                            (1 - alpha), InputImage))
                        Background_Image = Background_Updated
                        #img = np.asarray(Background_Image, dtype=np.uint8)
                        #img = np.multiply(Background_Substraction, 255)
                    if (self.imagedisplay == 1):
                        img = img
                    if (self.imagedisplay == 2):
                        img = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                    if (self.imagedisplay == 3):
                        img = np.asarray(Background_Image, dtype=np.uint8)
                    if (self.imagedisplay == 4):
                        bmg = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                        fmg = np.asarray(Background_Image, dtype=np.uint8)
                        # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                        img = cv2.addWeighted(fmg, 0.25,
                                              (np.where(bmg > fmg, img, 0)), 0.75, 0)

                    #imb = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                        #img = cv2.addWeighted(imb, 0.25,img, 0.75, 0)
                else:
                    first_imgF = True

                # Running average
                if self.subtractor == 9:
                    alpha = 0.9
                    Thu = 30
                    Ths = 30
                    Frame = img
                    if first_imgR:
                        Background_Image = Frame.astype(np.float32)
                        Background_Substraction = np.zeros((Frame.shape[0], Frame.shape[1]))
                        first_imgR = False
                    else:
                        Result_Comparison = cv2.absdiff(Frame.astype(np.float32), Background_Image)
                        Background_Substraction = np.where(Result_Comparison > Ths,
                                                           np.ones((Frame.shape[0], Frame.shape[1])), 0)
                        Background_Updated = cv2.add(np.multiply(alpha, Background_Image),
                                                     np.multiply((1 - alpha), Frame.astype(np.float32)))
                        Running_Average_Method = np.where(Result_Comparison < Thu,
                                                          Background_Updated, Background_Image)
                        Background_Image = Running_Average_Method
                        #img = np.multiply(Background_Substraction,255)
                    if (self.imagedisplay == 1):
                        img = img
                    if (self.imagedisplay == 2):
                        img = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                    if (self.imagedisplay == 3):
                        img = np.asarray(Background_Image, dtype=np.uint8)
                    if (self.imagedisplay == 4):
                        bmg = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                        fmg = np.asarray(Background_Image, dtype=np.uint8)
                        # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                        img = cv2.addWeighted(fmg, 0.25,
                                              (np.where(bmg > fmg, img, 0)), 0.75, 0)

                    #imb = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                        #img = cv2.addWeighted(imb, 0.25, img, 0.75, 0)
                        #img = np.asarray(Background_Image, dtype=np.uint8)
                else:
                    first_imgR = True

                if (self.lapse == True):
                    if (cont == 0):
                        img0 = img
                        cont = 1
                    else:
                        img0 = cv2.addWeighted(img0, 0.95, img, 0.05, 0)
                    img=img0
                    #self.iv.setImage(img, autoRange=False, autoLevels=False, autoHistogramRange=False)
                else:
                    cont = 0
                    #self.iv.setImage(img, autoRange=False, autoLevels=False, autoHistogramRange=False)
                self.iv.setImage(img, autoRange=False, autoLevels=False, autoHistogramRange=False)
                #create effect
                #if first_img:
                #    img0 =  img
                #else:
                #    img0  = cv2.addWeighted(img0, 0.95,img, 0.05, 0)



                #(self.hcam.getPropertyValue('internal_frame_rate'))
                #img = cv2.normalize(img, dst=None, alpha=0, beta=65535, norm_type=cv2.NORM_MINMAX)
                #self.iv.setImage(img, autoRange=False, autoLevels=False, autoHistogramRange=False)

                if first_img:
                    #self.iv.autoLevels()
                    first_img = False
                self.levels = self.hist.getLevels()


            except Exception as e:
                print(e)

        super(PreviewHamamatsu, self).end()

    def end(self):
        self._show_preview = False
        self.iv.close()
    def ImageBackground(self,inputImage,BGKimage,Dimage):
        #ImageDefault
        if(BGKimage == 1):
            img = inputImage
            if (Dimage == 1):
                img = inputImage

        if(BGKimage == 2):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbg.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbg.apply(inputImage)
                img = self.fgbg.getBackgroundImage()
            if (Dimage == 4):
                #fimg = self.fgbg.getBackgroundImage()
                #bimg = img
                bmg = self.fgbg.apply(inputImage)
                #img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(self.fgbg.getBackgroundImage(), 0.25,(np.where(bmg > self.fgbg.getBackgroundImage(), inputImage, 0)), 0.75, 0)
        if (BGKimage == 3):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgGMG.apply(inputImage)
            if (Dimage == 3):
                #self.ForegroundGMG
                #img = self.fgbgGMG.apply(inputImage)
                #img = self.fgbgGMG.getBackgroundImage()
                product = np.multiply(np.asarray(inputImage, dtype=np.float32),
                                     np.asarray(self.fgbgGMG.apply(inputImage), dtype=np.float32))
                img = np.where(product == 0, inputImage, self.ForegroundGMG)
                #img = self.ForegroundGMG
            if (Dimage == 4):
                #fimg = self.fgbgGMG.getBackgroundImage()
                #bimg = img
                bmg = self.fgbgGMG.apply(inputImage)
                product = np.multiply(np.asarray(inputImage, dtype=np.float32),
                                      np.asarray(self.fgbgGMG.apply(inputImage), dtype=np.float32))
                fmg = np.where(product == 0, inputImage, self.ForegroundGMG)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(fmg, 0.25,
                                      (np.where(bmg > fmg, inputImage, 0)), 0.75, 0)

        if (BGKimage == 4):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgGSOC.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbgGSOC.apply(inputImage)
                img = self.fgbgGSOC.getBackgroundImage()
            if (Dimage == 4):
                bmg = self.fgbgGSOC.apply(inputImage)
                fmg = cv2.cvtColor(self.fgbgGSOC.getBackgroundImage(), cv2.COLOR_BGR2GRAY)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(fmg, 0.25,
                                      (np.where(bmg > fmg, inputImage, 0)), 0.75, 0)

        if (BGKimage == 5):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgKNN.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbgKNN.apply(inputImage)
                img = self.fgbgKNN.getBackgroundImage()
            if (Dimage == 4):
                bmg = self.fgbgKNN.apply(inputImage)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(self.fgbgKNN.getBackgroundImage(), 0.25,
                                      (np.where(bmg > self.fgbgKNN.getBackgroundImage(), inputImage, 0)), 0.75, 0)

        if (BGKimage == 6):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgLSBP.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbgLSBP.apply(inputImage)
                img = self.fgbgLSBP.getBackgroundImage()
            if (Dimage == 4):
                bmg = self.fgbgLSBP.apply(inputImage)
                fmg = cv2.cvtColor(self.fgbgLSBP.getBackgroundImage(), cv2.COLOR_BGR2GRAY)
                #bmg = self.fgbgLSBP.apply(inputImage)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(fmg, 0.25,
                                      (np.where(bmg > fmg, inputImage, 0)), 0.75, 0)

        if (BGKimage == 7):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgMOG.apply(inputImage)
            if (Dimage == 3):
                #img = self.fgbgMOG.apply(inputImage)
                #img = self.fgbgMOG.getBackgroundImage()
                product = np.multiply(np.asarray(inputImage, dtype=np.float32),
                                      np.asarray(self.fgbgMOG.apply(inputImage), dtype=np.float32))
                img = np.where(product == 0, inputImage, self.ForegroundMOG)
                #img = self.ForegroundMOG
            if (Dimage == 4):
                bmg = self.fgbgMOG.apply(inputImage)
                product = np.multiply(np.asarray(inputImage, dtype=np.float32),
                                      np.asarray(self.fgbgMOG.apply(inputImage), dtype=np.float32))
                fmg = np.where(product == 0, inputImage, self.ForegroundMOG)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(fmg, 0.25,
                                      (np.where(bmg > fmg, inputImage, 0)), 0.75, 0)

        if (BGKimage == 8):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgMOG2.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbgMOG2.apply(inputImage)
                img = self.fgbgMOG2.getBackgroundImage()
            if (Dimage == 4):
                bmg = self.fgbgMOG2.apply(inputImage)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(self.fgbgMOG2.getBackgroundImage(), 0.25,
                                      (np.where(bmg > self.fgbgMOG2.getBackgroundImage(), inputImage, 0)), 0.75, 0)
        return img




class AcquireHamamatsu(BaseHamamatsu):
    def __init__(self, parameters, threading_queue, duration, FlagEndFrame, FlagEndTime, NumberOfFrames):
        kwargs = parameters
        BaseHamamatsu.__init__(self, **kwargs)
        self.q = threading_queue
        self.duration = duration
        self.FlagEndFrame = FlagEndFrame
        self.FlagEndTime = FlagEndTime
        self.NumberofFrames = NumberOfFrames
        self._acquire = True
        self.numberofFrames = 0
        self.timeFrames = 0


    def run(self):
        frame_num = 0
        self.hcam.startAcquisition()
        CurrentTime = time.time()
        self.stop_time = time.time() + self.duration
        if(self.FlagEndFrame == True):
            while (frame_num < self.NumberofFrames) and self._acquire:
                try:
                    # self.lens.focalpower( <<appropriate focal power>> )

                    # << Modulo calculation to find the next focal power to adjust to according to focal_interval >>

                    # time.sleep(0.014) # Wait 14ms for the lens to adjust to the right focal power

                    # <<** might be possible to lower this time because of small stack intervals
                    # and use larger wait times only when beginning the next stack!! ** >>

                    self.q.put(self.get_grey_values())
                    print('Read frame num ' + str(frame_num) + '\r')
                    frame_num += 1
                    #print(time.time()-CurrentTime)
                    self.numberofFrames = frame_num
                    #self.timeFrames = time.time() - CurrentTime


                except KeyboardInterrupt:
                    self.end()
                    raise KeyboardInterrupt

                except Exception as e:
                    if type(e) is not IndexError:
                        print('Something went wrong during ' +
                              'acquisition of frame num: ' + str(frame_num)
                              + '\n' + str(traceback.format_exc()))
        if(self.FlagEndTime == True):
            while (time.time() < self.stop_time) and self._acquire:
                try:
                    # self.lens.focalpower( <<appropriate focal power>> )

                    # << Modulo calculation to find the next focal power to adjust to according to focal_interval >>

                    # time.sleep(0.014) # Wait 14ms for the lens to adjust to the right focal power

                    # <<** might be possible to lower this time because of small stack intervals
                    # and use larger wait times only when beginning the next stack!! ** >>

                    self.q.put(self.get_grey_values())
                    print('Read frame num ' + str(frame_num) + '\r')
                    frame_num += 1
                    #print(time.time()-CurrentTime)
                    #self.numberofFrames = frame_num
                    #self.timeFrames = time.time()-CurrentTime

                except KeyboardInterrupt:
                    self.end()
                    raise KeyboardInterrupt

                except Exception as e:
                    if type(e) is not IndexError:
                        print('Something went wrong during ' +
                              'acquisition of frame num: ' + str(frame_num)
                              + '\n' + str(traceback.format_exc()))




        self.q.put('done')
        super(AcquireHamamatsu, self).end()

    def end(self):
        self._acquire = False


# TODO: TRY MULTIPROCESSING HERE SINCE I'M ONLY SENDING A NUMPY ARRAY AND NOT HCAM OBJECT !!!!!!!!!!
class WriterHamamatsu(BaseWriter, BasePreview):
    """Use for Hamamatsu Cameras"""

    def __init__(self, threading_queue, filename, compression_level, levels, metadata):
        BaseWriter.__init__(self, threading_queue=threading_queue, filename=filename,
                            compression_level=compression_level, levels=levels, metadata=metadata)
        BasePreview.__init__(self)


        #self.iv.setLevels(levels[0], levels[1])
        self.iv.setLevels(0, 260)
        #self.LUT_8bit = ImageFuncs.create_LUT_8bit(levels, 16)

        self.write = True
        self.subtractor = self.metadata['subtractor']
        self.imagedisplay = self.metadata['image_display']
        self.lapse = self.metadata['lapse']
        self._show_preview = True
        # BACKGROUND CNT
        self.fgbg = cv2.bgsegm.createBackgroundSubtractorCNT(minPixelStability=15,
                                                             useHistory=True,
                                                             maxPixelStability=15 * 60,
                                                             isParallel=True)
        # BACKGROUND GMG
        self.fgbgGMG = cv2.bgsegm.createBackgroundSubtractorGMG(initializationFrames=1,
                                                                decisionThreshold=0.8)
        # BackgroundGSOC
        self.fgbgGSOC = cv2.bgsegm.createBackgroundSubtractorGSOC(nSamples=20,
                                                                  replaceRate=0.003,
                                                                  propagationRate=0.01,
                                                                  hitsThreshold=32,
                                                                  alpha=0.01,
                                                                  beta=0.0022,
                                                                  blinkingSupressionDecay=0.1,
                                                                  blinkingSupressionMultiplier=0.1,
                                                                  noiseRemovalThresholdFacBG=0.0004,
                                                                  noiseRemovalThresholdFacFG=0.0008)
        # BackgroundKNN
        self.fgbgKNN = cv2.createBackgroundSubtractorKNN(history=500,
                                                         dist2Threshold=400.0,
                                                         detectShadows=True)
        # BackgroundLSBP
        self.fgbgLSBP = cv2.bgsegm.createBackgroundSubtractorLSBP(nSamples=20,
                                                                  LSBPRadius=16,
                                                                  Tlower=2.0,
                                                                  Tupper=32.0,
                                                                  Tinc=1.0,
                                                                  Tdec=0.05,
                                                                  Rscale=10.0,
                                                                  Rincdec=0.005,
                                                                  noiseRemovalThresholdFacBG=0.0004,
                                                                  noiseRemovalThresholdFacFG=0.0008,
                                                                  LSBPthreshold=8,
                                                                  minCount=2)
        # BackgroundMOG
        self.fgbgMOG = cv2.bgsegm.createBackgroundSubtractorMOG(history=200,
                                                                nmixtures=5,
                                                                backgroundRatio=0.7,
                                                                noiseSigma=0)
        self.fgbgMOG2 = cv2.createBackgroundSubtractorMOG2(history=500,
                                                           varThreshold=16,
                                                           detectShadows=True)

    def run(self):
        img_num = 0
        CurrentTime = time.time()
        #flag for functions
        first_img = True
        first_imgR = True
        first_imgFL = True
        first_imgF = True
        first_imgMOG = True
        first_imgGMG = True
        cont = 0
        while self.write:
            if not self.q.not_empty:
                continue

            cam_data = self.q.get()

            if type(cam_data) is str:
                if cam_data == 'done':
                    break

            else:

                try:
                    ##oscar
                    #img = np.reshape(cam_data, (1200, 1920))
                    #print(self.metadata)
                    Vsize = int(self.metadata['width'])
                    Hsize = int(self.metadata['height'])
                    #print('size v')
                    #print(Vsize)
                    #print('size h')
                    #print(Hsize)
                    img = np.reshape(cam_data, (Vsize, Hsize))
                    img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
                    #print(img.dtype)
                    #img = cv2.convertScaleAbs(img, alpha=(256.0 / 256.0))
                    bits = int(self.metadata['bits'])
                    #print('bits used')
                    #print(bits)
                    if (bits == 8):
                        wbits = 256.0
                    if (bits == 10):
                        wbits = 1024.0
                    if (bits == 12):
                        wbits = 4096.0
                    if (bits == 14):
                        wbits = 16384.0
                    if (bits == 16):
                        wbits = 65536.0

                    img = cv2.convertScaleAbs(img, alpha=(256.0 / wbits))
                    #img = cv2.normalize(img, dst=None, alpha=0, beta=65535, norm_type=cv2.NORM_MINMAX)
                    #img = np.reshape(cam_data, (2048, 2048))
                    if (self.subtractor <= 8):
                        if (self.subtractor == 3):
                            if (self.subtractor == 3 and self.imagedisplay == 3):
                                if first_imgGMG:
                                    self.ForegroundGMG = img
                                    first_imgGMG = False
                                else:
                                    self.ForegroundGMG = self.ImageBackground(img, self.subtractor, self.imagedisplay)
                                img = self.ForegroundGMG
                            else:
                                first_imgGMG = True
                                img = self.ImageBackground(img, self.subtractor, self.imagedisplay)
                        if (self.subtractor == 7):
                            if (self.subtractor == 7 and self.imagedisplay == 3):
                                if first_imgMOG:
                                    self.ForegroundMOG = img
                                    first_imgMOG = False
                                else:
                                    self.ForegroundMOG = self.ImageBackground(img, self.subtractor, self.imagedisplay)
                                img = self.ForegroundMOG
                            else:
                                first_imgMOG = True
                                img = self.ImageBackground(img, self.subtractor, self.imagedisplay)
                        if (self.subtractor != 3 and self.subtractor != 7):
                            first_imgGMG = True
                            first_imgMOG = True
                            img = self.ImageBackground(img, self.subtractor, self.imagedisplay)


                    # Running fuzzy  lineal
                    if (self.subtractor == 10):
                        Thu = 30
                        Ths = 5
                        Thfs = 0.4
                        alphamin = 0.9
                        Height, Width = img.shape
                        InputImage = np.asarray(img, dtype=np.float32)
                        if first_imgFL:
                            Background_Image = InputImage
                            Background_Updated = np.zeros((Height, Width))
                            Background_Updated = np.asarray(Background_Updated,
                                                            dtype=np.float32)
                            Result_Comparison = np.zeros((Height, Width))
                            Result_Comparison = np.asarray(Result_Comparison,
                                                           dtype=np.float32)
                            Background_Substraction = np.zeros((Height, Width))
                            Background_Substraction = np.asarray(Result_Comparison,
                                                                 dtype=np.float32)
                            alpha = np.zeros((Height, Width))
                            alpha = np.asarray(Result_Comparison,
                                               dtype=np.float32)
                            Saturating_Limiter = np.zeros((Height, Width))
                            Saturating_Limiter = np.asarray(Saturating_Limiter, dtype=np.float32)
                            Fuzzy_Background_Substraction = np.zeros((Height, Width))
                            Fuzzy_Background_Substraction = np.asarray(Saturating_Limiter, dtype=np.float32)
                            first_imgFL = False

                        else:
                            Result_Comparison = np.absolute(np.subtract(InputImage,
                                                                        Background_Image))
                            Saturating_Limiter = np.divide(Result_Comparison, Ths)
                            Fuzzy_Background_Substraction = np.where(Result_Comparison > Ths,
                                                                     np.ones((Height, Width)),
                                                                     Saturating_Limiter)
                            Abs_LPF_Fuzzy_Background_Substraction = np.absolute(cv2.blur(
                                Fuzzy_Background_Substraction, (3, 3)))

                            Background_Substraction = np.where(Abs_LPF_Fuzzy_Background_Substraction > Thfs,
                                                               np.ones((Height, Width)), 0)
                            alpha = 1 + np.multiply(0.1, (np.subtract(Fuzzy_Background_Substraction, 1)))
                            Background_Updated = np.add(np.multiply(alpha, Background_Image), np.multiply(
                                (1 - alpha), InputImage))
                            Background_Image = Background_Updated
                        if (self.imagedisplay == 1):
                            img = img
                        if (self.imagedisplay == 2):
                            img = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                        if (self.imagedisplay == 3):
                            img = np.asarray(Background_Image, dtype=np.uint8)
                        if (self.imagedisplay == 4):
                            bmg = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                            fmg = np.asarray(Background_Image, dtype=np.uint8)
                            # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                            img = cv2.addWeighted(fmg, 0.25,
                                                  (np.where(bmg > fmg, img, 0)), 0.75, 0)
                    else:
                        first_imgFL = True

                    # Running Fuzzy logic
                    if (self.subtractor == 11):
                        Thu = 30
                        Ths = 30
                        Thfs = 0.4
                        alphamin = 0.9
                        Height, Width = img.shape
                        InputImage = np.asarray(img, dtype=np.float32)
                        if first_imgF:
                            Background_Image = InputImage
                            Background_Updated = np.zeros((Height, Width))
                            Background_Updated = np.asarray(Background_Updated,
                                                            dtype=np.float32)
                            Result_Comparison = np.zeros((Height, Width))
                            Result_Comparison = np.asarray(Result_Comparison,
                                                           dtype=np.float32)
                            Background_Substraction = np.zeros((Height, Width))
                            Background_Substraction = np.asarray(Result_Comparison,
                                                                 dtype=np.float32)
                            alpha = np.zeros((Height, Width))
                            alpha = np.asarray(Result_Comparison,
                                               dtype=np.float32)
                            Saturating_Limiter = np.zeros((Height, Width))
                            Saturating_Limiter = np.asarray(Saturating_Limiter, dtype=np.float32)
                            Fuzzy_Background_Substraction = np.zeros((Height, Width))
                            Fuzzy_Background_Substraction = np.asarray(Saturating_Limiter, dtype=np.float32)
                            first_imgF = False
                        else:
                            Result_Comparison = np.absolute(np.subtract(InputImage,
                                                                        Background_Image))
                            Saturating_Limiter = np.divide(Result_Comparison, Ths)
                            Fuzzy_Background_Substraction = np.where(Result_Comparison > Ths,
                                                                     np.ones((Height, Width)),
                                                                     Saturating_Limiter)
                            Abs_LPF_Fuzzy_Background_Substraction = np.absolute(cv2.blur(
                                Fuzzy_Background_Substraction, (3, 3)))
                            Background_Substraction = np.where(Abs_LPF_Fuzzy_Background_Substraction > Thfs,
                                                               np.ones((Height, Width)), 0)
                            alpha = np.subtract(1, np.multiply(
                                (1 - alphamin), np.exp(np.multiply(-5, Fuzzy_Background_Substraction))))
                            Background_Updated = np.add(np.multiply(alpha, Background_Image), np.multiply(
                                (1 - alpha), InputImage))
                            Background_Image = Background_Updated
                            # img = np.asarray(Background_Image, dtype=np.uint8)
                            # img = np.multiply(Background_Substraction, 255)
                        if (self.imagedisplay == 1):
                            img = img
                        if (self.imagedisplay == 2):
                            img = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                        if (self.imagedisplay == 3):
                            img = np.asarray(Background_Image, dtype=np.uint8)
                        if (self.imagedisplay == 4):
                            bmg = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                            fmg = np.asarray(Background_Image, dtype=np.uint8)
                            # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                            img = cv2.addWeighted(fmg, 0.25,
                                                  (np.where(bmg > fmg, img, 0)), 0.75, 0)
                    else:
                        first_imgF = True

                    # Running average
                    if self.subtractor == 9:
                        alpha = 0.9
                        Thu = 30
                        Ths = 30
                        Frame = img
                        if first_imgR:
                            Background_Image = Frame.astype(np.float32)
                            Background_Substraction = np.zeros((Frame.shape[0], Frame.shape[1]))
                            first_imgR = False
                        else:
                            Result_Comparison = cv2.absdiff(Frame.astype(np.float32), Background_Image)
                            Background_Substraction = np.where(Result_Comparison > Ths,
                                                               np.ones((Frame.shape[0], Frame.shape[1])), 0)
                            Background_Updated = cv2.add(np.multiply(alpha, Background_Image),
                                                         np.multiply((1 - alpha), Frame.astype(np.float32)))
                            Running_Average_Method = np.where(Result_Comparison < Thu,
                                                              Background_Updated, Background_Image)
                            Background_Image = Running_Average_Method
                            # img = np.multiply(Background_Substraction,255)
                        if (self.imagedisplay == 1):
                            img = img
                        if (self.imagedisplay == 2):
                            img = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                        if (self.imagedisplay == 3):
                            img = np.asarray(Background_Image, dtype=np.uint8)
                        if (self.imagedisplay == 4):
                            bmg = np.asarray(np.multiply(Background_Substraction, 255), dtype=np.uint8)
                            fmg = np.asarray(Background_Image, dtype=np.uint8)
                            # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                            img = cv2.addWeighted(fmg, 0.25,
                                                  (np.where(bmg > fmg, img, 0)), 0.75, 0)
                    else:
                        first_imgR = True

                    if (self.lapse == True):
                        if (cont == 0):
                            img0 = img
                            cont = 1
                        else:
                            img0 = cv2.addWeighted(img0, 0.95, img, 0.05, 0)
                        img = img0

                    else:
                        cont = 0

                    try:
                        self.iv.setImage(img, autoRange=False, autoLevels=False, autoHistogramRange=False)
                    except Exception as e:
                        print('Error displaying an image: ' + str(e))




                    #img = ImageFuncs.apply_8bit_LUT(img, self.LUT_8bit)
                    #img = ImageFuncs.apply_8bit_LUT(img, self.LUT_8bit)
                    import imageio
                    #self.tiff_writer.save(img, compress=self.comp_lev)

                    #from PIL import Image, TiffImagePlugin


                    filename=self.filename.rsplit('.', 1)[0]
                    if img_num < 10:
                        new_num = "00000"+str(img_num)
                    if img_num >=10 and img_num < 100:
                        new_num = "0000" + str(img_num)
                    if img_num >= 100 and img_num < 1000:
                        new_num = "000" + str(img_num)
                    if img_num >= 1000 and img_num < 10000:
                        new_num = "00" + str(img_num)
                    if img_num >= 10000 and img_num < 100000:
                        new_num = "0" + str(img_num)
                    if img_num >= 100000 :
                        new_num = str(img_num)


                    path = (filename + str(new_num) + '.tiff')
                    img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)

                    imageio.imwrite(path, img)


                    print('qsize is: ' + str(self.q.qsize()) + '\r')
                    print('wrote ImgNum: ' + str(img_num)  + '\r')

                    self.q.task_done()
                    if (img_num == 0):
                        initialTime = time.time() - CurrentTime
                    img_num += 1

                    print(time.time() - CurrentTime)
                    finaltime = (time.time() - CurrentTime)-initialTime

                except KeyboardInterrupt:
                    break
        self.metadata['NumberOfFrames']=img_num
        self.metadata['LapseTime']=finaltime
        #self.tiff_writer.close()
        self.save_metadata(self.filename)


    def end(self):
        self.write = False

    def ImageBackground(self,inputImage,BGKimage,Dimage):
        #ImageDefault
        if(BGKimage == 1):
            img = inputImage
            if (Dimage == 1):
                img = inputImage

        if(BGKimage == 2):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbg.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbg.apply(inputImage)
                img = self.fgbg.getBackgroundImage()
            if (Dimage == 4):
                # fimg = self.fgbg.getBackgroundImage()
                # bimg = img
                bmg = self.fgbg.apply(inputImage)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(self.fgbg.getBackgroundImage(), 0.25,
                                      (np.where(bmg > self.fgbg.getBackgroundImage(), inputImage, 0)), 0.75, 0)

        if (BGKimage == 3):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgGMG.apply(inputImage)
            if (Dimage == 3):
                # self.ForegroundGMG
                # img = self.fgbgGMG.apply(inputImage)
                # img = self.fgbgGMG.getBackgroundImage()
                product = np.multiply(np.asarray(inputImage, dtype=np.float32),
                                      np.asarray(self.fgbgGMG.apply(inputImage), dtype=np.float32))
                img = np.where(product == 0, inputImage, self.ForegroundGMG)
            if (Dimage == 4):
                # fimg = self.fgbgGMG.getBackgroundImage()
                # bimg = img
                bmg = self.fgbgGMG.apply(inputImage)
                product = np.multiply(np.asarray(inputImage, dtype=np.float32),
                                      np.asarray(self.fgbgGMG.apply(inputImage), dtype=np.float32))
                fmg = np.where(product == 0, inputImage, self.ForegroundGMG)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(fmg, 0.25,
                                      (np.where(bmg > fmg, inputImage, 0)), 0.75, 0)

        if (BGKimage == 4):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgGSOC.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbgGSOC.apply(inputImage)
                img = self.fgbgGSOC.getBackgroundImage()
            if (Dimage == 4):
                bmg = self.fgbgGSOC.apply(inputImage)
                fmg = cv2.cvtColor(self.fgbgGSOC.getBackgroundImage(), cv2.COLOR_BGR2GRAY)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(fmg, 0.25,
                                      (np.where(bmg > fmg, inputImage, 0)), 0.75, 0)

        if (BGKimage == 5):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgKNN.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbgKNN.apply(inputImage)
                img = self.fgbgKNN.getBackgroundImage()
            if (Dimage == 4):
                bmg = self.fgbgKNN.apply(inputImage)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(self.fgbgKNN.getBackgroundImage(), 0.25,
                                      (np.where(bmg > self.fgbgKNN.getBackgroundImage(), inputImage, 0)), 0.75, 0)

        if (BGKimage == 6):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgLSBP.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbgLSBP.apply(inputImage)
                img = self.fgbgLSBP.getBackgroundImage()
            if (Dimage == 4):
                bmg = self.fgbgLSBP.apply(inputImage)
                fmg = cv2.cvtColor(self.fgbgLSBP.getBackgroundImage(), cv2.COLOR_BGR2GRAY)
                # bmg = self.fgbgLSBP.apply(inputImage)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(fmg, 0.25,
                                      (np.where(bmg > fmg, inputImage, 0)), 0.75, 0)

        if (BGKimage == 7):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgMOG.apply(inputImage)
            if (Dimage == 3):
                # img = self.fgbgMOG.apply(inputImage)
                # img = self.fgbgMOG.getBackgroundImage()
                product = np.multiply(np.asarray(inputImage, dtype=np.float32),
                                      np.asarray(self.fgbgMOG.apply(inputImage), dtype=np.float32))
                img = np.where(product == 0, inputImage, self.ForegroundMOG)

            if (Dimage == 4):
                bmg = self.fgbgMOG.apply(inputImage)
                product = np.multiply(np.asarray(inputImage, dtype=np.float32),
                                      np.asarray(self.fgbgMOG.apply(inputImage), dtype=np.float32))
                fmg = np.where(product == 0, inputImage, self.ForegroundMOG)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(fmg, 0.25,
                                      (np.where(bmg > fmg, inputImage, 0)), 0.75, 0)

        if (BGKimage == 8):
            if (Dimage == 1):
                img = inputImage
            if (Dimage == 2):
                img = self.fgbgMOG2.apply(inputImage)
            if (Dimage == 3):
                img = self.fgbgMOG2.apply(inputImage)
                img = self.fgbgMOG2.getBackgroundImage()
            if (Dimage == 4):
                bmg = self.fgbgMOG2.apply(inputImage)
                # img = cv2.addWeighted(self.fgbg.apply(inputImage), 0.25,inputImage, 0.75, 0)
                img = cv2.addWeighted(self.fgbgMOG2.getBackgroundImage(), 0.25,
                                      (np.where(bmg > self.fgbgMOG2.getBackgroundImage(), inputImage, 0)), 0.75, 0)
        return img
