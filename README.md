# PythonControlHamamatsuCamera_With_ImageProcessing
The exponential growth of integrated circuits fabrication has made the yield of semiconductor processes an important area for controlling and monitoring parameters such as temperature, humidity and Air Molecular Contamination (AMC). Contamination-free manufacturing has become the most critical factor in semiconductor high-tech processes, especially integrated circuit manufacturing. This study, we investigated the contaminant control, which involves not only particle concentration control but also monitoring of AMC. Particle concentration is controlled by filters most of them are located in a specific points of a clean room, on the other hand, AMC must be removed by purging method, the removal quality is going to depend on the airflow pattern inside the Equipment Front-End Module (EFEM) and the Front Opening Unified Pod (FOUP), the majority  of semiconductor processes applications, the airflow is often disturbed because of the different arrangement methods in the EFEM, it produces pollution inside the FOUP. 
In order to control the particle contamination and air flow monitoring, this research is going to provide an efficient way for visualization and data acquisition by using image processing with a future approach of deep neural network. To carry out this research we aimed at the light scattering of particles and air flow. The system proposed has been developed based on new technologies like CMOS camera sensors, slide rotational beam laser, and the link between programming algorithms with free platforms. A laser sheet generator was used to increase the light reflection of particles, air flow, a high sensitivity camera was essential part of this experiment for recording videos. The data (frames images) are going to be processed principally by algorithms which were tested in Matlab and implemented in Python / C++. 
Firstly, Matlab was used as testing software platform to control and process the frames taken by the CMOS camera, however the speed communication between camera and computer was slower than the required frame rate, (in order to have an acceptable PIV or Flow visualization a minimal frame rate of 25 fps is required), therefore the algorithm implementation was programed in Python. Some modules such as Numpy, OpenCV, Scikit were used to operate the images as array, which made much faster the image processing in real time.  The future approach and final step is to implement a machine learning library Scikit-learn to classifier the video from a foreground and background. 
Algorithm:
One of most important part of moving object detection algorithms is background subtraction. For video monitoring a background model is the extraction of background image and updating it during the lapse of the video. There are various methods for background subtraction:
	Basic Background modelling: average and median method
	Statistical Background modelling: the single Gaussian or mixture of Gaussian
	Background Estimation: Kalman Filter and Tchebychev filter.  
Logic:
The simplest background subtraction is the running average, the background detection is the absolute value of the difference of current frame and previous background frame. 

〖Background Subtraction〗_((i,j))={■(■(1&if |〖Input Frame(t)〗_((i,j) )-〖Background(t-1)〗_((i,j) ) |>threshold)@■(0&               otherwise                                                                                     ))}	


In order to update the background during the next frames the method proposed is: 

〖Background Subtraction Updated〗_((i,j))={■(■(alpha*〖Background(t-1)〗_((i,j) )+(1-alpha)*〖Input Frame(t-1)〗_((i,j) )&if |〖Input Frame(t)〗_((i,j) )-〖Background(t-1)〗_((i,j) ) |<threshold)@■(〖Background(t-1)〗_((i,j) )&               otherwise                                                                                     ))}
